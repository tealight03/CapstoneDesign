import os
import re
import torch
import uuid
import datetime
import torch.nn.functional as F
from markdown import markdown
from weasyprint import HTML
from openai import OpenAI
from fastapi import FastAPI, Body
from pydantic import BaseModel, Field
from docx import Document
from fastapi.responses import FileResponse
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# FastAPI ì•± ìƒì„±(Swagger ë¬¸ì„œ ì •ë³´ í¬í•¨í•¨)
app = FastAPI(
    title = 'AI ê¸°ë°˜ ì½”ë“œ ë³´ì•ˆ ë¶„ì„ê¸° API',
    description = "CodeBERTì™€ GPT APIë¥¼ í™œìš©í•´ ì½”ë“œì˜ ë³´ì•ˆ ì·¨ì•½ì ì„ ìë™ íƒì§€í•˜ê³ , ë³´ì•ˆ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” APIì…ë‹ˆë‹¤.",
    version = "1.0.0",
    contact = {
        "email": "davin0706@gmail.com",
        "url": "https://github.com/tealight03/CapstoneDesign"
    }
)

# ì…ë ¥ ìŠ¤í‚¤ë§ˆ
class CodeRequest(BaseModel):
    code: str = Field(
        ...,
        description = "ë³´ì•ˆ ë¶„ì„í•  ì†ŒìŠ¤ ì½”ë“œ (Python)",
        example = "user_input = input('Enter ID: ')\nsql = 'SELECT * FROM users WHERE id = ' + user_input"
    )
    
# ì‘ë‹µ ìŠ¤í‚¤ë§ˆ
class AnalyzeResponse(BaseModel):
    prediction: str = Field(..., description="ë¶„ì„ ê²°ê³¼ ë©”ì‹œì§€")
    label: str = Field(..., description="ì˜ˆì¸¡ëœ ë³´ì•ˆ ì·¨ì•½ì  ë¼ë²¨ (ì˜ˆ: SQL_Injection, Safe_Code ë“±)")
    security_score: int = Field(..., description="0~100 ì‚¬ì´ì˜ ë³´ì•ˆ ì ìˆ˜ (ë‚®ì„ìˆ˜ë¡ ì·¨ì•½í•¨)")
    report: str = Field(..., description="GPT APIê°€ ì‘ì„±í•œ ë³´ì•ˆ ë¶„ì„ ë³´ê³ ì„œ")
    model_reference: dict = Field(..., description="CodeBERT ëª¨ë¸ì˜ ì›ë˜ ì˜ˆì¸¡ ê²°ê³¼")

# ëª¨ë¸ ê²½ë¡œë¥¼ Hugging Face ê²½ë¡œë¡œ ì„¤ì •
model_path = "davin0706/codebert-finetuned-v5"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)

# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

# âœ… ì ìˆ˜ ë§¤í•‘
score_map = {
    0: {"label": "SQL_Injection", "score": 30, "msg": "âš ï¸ SQL Injection ì·¨ì•½ì  ê°ì§€"},
    1: {"label": "Hardcoded_Password", "score": 30, "msg": "âš ï¸ Hardcoded Password ê°ì§€"},
    2: {"label": "XSS", "score": 30, "msg": "âš ï¸ XSS ì·¨ì•½ì  ê°ì§€"},
    3: {"label": "Safe_Code", "score": 100, "msg": "âœ… ì™„ì „í•œ ë°©ì–´ ì½”ë“œ (Safe Code)"},
    4: {"label": "Other", "score": 70, "msg": "âš ï¸ ì ì¬ì  ì·¨ì•½ì ì´ ìˆëŠ” ì½”ë“œ (Other)"}
}

# ë¼ë²¨ í™•ì¸ í•¨ìˆ˜
def resolve_final_label_score(bert_label: str, gpt_label: str = None) -> dict:
    print(f"ğŸ” [ë¼ë²¨ ê²°ì •] CodeBERT ë¼ë²¨: '{bert_label}', GPT ë¼ë²¨: '{gpt_label}'")
    final_entry = None

    # 1. GPT ë¼ë²¨ì´ ì¡´ì¬í•˜ê³  CodeBERTì™€ ë‹¤ë¥´ë©´ ìš°ì„  ì ìš© ì‹œë„
    if gpt_label and gpt_label.lower() != bert_label.lower():
        for entry in score_map.values():
            if entry["label"].lower() == gpt_label.lower():
                final_entry = entry
                print(f"âœ… [GPT ë¼ë²¨ ì±„íƒ] '{gpt_label}'ì— í•´ë‹¹í•˜ëŠ” ë¼ë²¨ ì •ë³´ ì ìš©")
                break
        if not final_entry:
            print(f"âš ï¸ [GPT ë¼ë²¨ ë¯¸ì¼ì¹˜] GPT ë¼ë²¨ '{gpt_label}'ì´ ìœ íš¨í•˜ì§€ ì•ŠìŒ. CodeBERT ê²°ê³¼ë¡œ fallback")

    # 2. fallback: CodeBERT ë¼ë²¨ ê¸°ë°˜
    if not final_entry:
        for entry in score_map.values():
            if entry["label"].lower() == bert_label.lower():
                final_entry = entry
                print(f"ğŸ” [Fallback] CodeBERT ë¼ë²¨ '{bert_label}' ê¸°ë°˜ ê²°ê³¼ ì ìš©")
                break

    if final_entry:
        print(f"ğŸ [ìµœì¢… ì„ íƒ] ë¼ë²¨: {final_entry['label']}, ì ìˆ˜: {final_entry['score']}, ë©”ì‹œì§€: {final_entry['msg']}")
    else:
        print("âŒ [ì—ëŸ¬] ë¼ë²¨ ë§¤í•‘ ì‹¤íŒ¨: ê¸°ë³¸ê°’ ë°˜í™˜ ì˜ˆì •")

    return final_entry


# âœ… ë³´ì•ˆ ë¶„ì„ í•¨ìˆ˜
def analyze_code(code_snippet: str):
    inputs = tokenizer(code_snippet, return_tensors="pt", truncation=True, padding="max_length", max_length=128)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = F.softmax(logits, dim=1)[0]
        predicted = torch.argmax(probs).item()

        # Safe vs Other í›„ì²˜ë¦¬
        if predicted == 3:
            if probs[4].item() > 0.3 and probs[3].item() < 0.7:
                predicted = 4

    return {
        "prediction": score_map[predicted]["msg"],
        "label": score_map[predicted]["label"],
        "security_score": score_map[predicted]["score"]
    }

# âœ… GPT ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜
def generate_report(code_snippet: str, label: str) -> str:
    prompt = f"""
ë‹¹ì‹ ì€ ë³´ì•ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ëª¨ë¸ ë¶„ì„ ê²°ê³¼, ì•„ë˜ì˜ ì†ŒìŠ¤ ì½”ë“œì—ì„œ ê°ì§€ëœ ì·¨ì•½ì ì€ **'{label}'** ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ ì†ŒìŠ¤ ì½”ë“œë¥¼ ìƒì„¸íˆ ë¶„ì„í•´ì„œ ì˜ˆìƒë˜ëŠ” ì·¨ì•½ì  ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

[ì·¨ì•½ ì½”ë“œ]
{code_snippet.rstrip()}


ğŸ“Œ **1. ì·¨ì•½ì  ì„¤ëª…**
í•´ë‹¹ ì·¨ì•½ì ì´ ë°œìƒí•œ ì´ìœ ì™€ ì½”ë“œ êµ¬ì¡°ìƒ ë¬¸ì œì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"í•´ë‹¹ ì½”ë“œëŠ” ~~~ ì·¨ì•½ì ì´ ìˆëŠ” ê²ƒìœ¼ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤." ì™€ ê°™ì€ ë¬¸ì¥ìœ¼ë¡œ ë¬¸ì¥ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.

ğŸ’£ **2. ê³µê²© ì‹œë‚˜ë¦¬ì˜¤**
ê³µê²©ìê°€ í•´ë‹¹ ì½”ë“œë¥¼ ì–´ë–»ê²Œ ì•…ìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ğŸ›  **3. ë³´ì™„ ë°©ë²• ë° ê°œì„ ëœ ì½”ë“œ ì˜ˆì‹œ**
ë³´ì™„ ë°©ë²•ì„ ì„¤ëª…í•˜ê³ , ë³´ì™„ëœ ì½”ë“œ ì˜ˆì‹œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.

âœ… **4. ìš”ì•½ëœ ë³´ì•ˆ ê¶Œê³ ì‚¬í•­**
ìš”ì•½ëœ ê¶Œê³ ì‚¬í•­ì„ **ë¦¬ìŠ¤íŠ¸ í˜•ì‹**ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

---

ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ğŸ“„ **ë³´ì•ˆ ë¶„ì„ ë¦¬í¬íŠ¸**

---
"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant for code security analysis."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
        max_tokens=1200
    )
    return response.choices[0].message.content

# GPT API ê²°ê³¼ì—ì„œ label ì¶”ì¶œ
def extract_label_from_report(report: str) -> str:
    try:
        # ì •ê·œì‹ìœ¼ë¡œ ì·¨ì•½ì  ë¼ë²¨ ì¶”ì¶œ ì‹œë„
        match = re.search(r"ì·¨ì•½ì (?:ì€|ì´)?[^ê°€-í£]{0,5}\*\*['\"]?(.+?)['\"]?\*\*", report)
        if match:
            candidate = match.group(1).strip().replace(" ", "_")
            print(f"ğŸ” [ì •ê·œì‹ ë§¤ì¹­] ì¶”ì¶œëœ candidate: '{candidate}'")

            # ì•ˆì „í•œ ì½”ë“œë¡œ íŒëª…ë˜ì—ˆì„ ê²½ìš°
            if candidate == "Safe_Code":
                for item in score_map.values():
                    if item["label"] != "Safe_Code" and item["label"] in report:
                        print(f"âš ï¸ Safe_Code ì˜¤íƒ ê°ì§€, ëŒ€ì²´ ë¼ë²¨ ì‚¬ìš©: '{item['label']}'")
                        return item["label"]
            print(f"âœ… ìµœì¢… ì„ íƒëœ ë¼ë²¨ (ì •ê·œì‹ ê¸°ì¤€): '{candidate}'")
            return candidate

        # fallback: ì •ê·œì‹ ì‹¤íŒ¨ ì‹œ, ë³¸ë¬¸ ë‚´ì—ì„œ ìˆ˜ë™ íƒìƒ‰
        for item in score_map.values():
            if item["label"] in report:
                print(f"ğŸ” [ë³¸ë¬¸ íƒìƒ‰] '{item['label']}' ë¼ë²¨ì´ ë³´ê³ ì„œì— ì§ì ‘ í¬í•¨ë˜ì–´ ìˆìŒ")
                return item["label"]

    except Exception as e:
        print(f"âš ï¸ extract_label_from_report ì˜ˆì™¸ ë°œìƒ: {e}")
    
    print("âŒ ë¼ë²¨ ì¶”ì¶œ ì‹¤íŒ¨: None ë°˜í™˜")
    return None

# / ë¥¼ ì„œë²„ í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ë¡œ í™œìš©
@app.get("/", summary="API ì„œë²„ í—¬ìŠ¤ ì²´í¬")
def root():
    return {"message": "ğŸš€ Code Security Analyzer is running!"}

# âœ… API ì—”ë“œí¬ì¸íŠ¸
@app.post("/analyze", summary = "ì†ŒìŠ¤ ì½”ë“œ ë³´ì•ˆ ì·¨ì•½ì  ë¶„ì„", response_model = AnalyzeResponse)
def analyze(request: CodeRequest = Body(...)):
    # 1. CodeBERT ê²°ê³¼
    bert_result = analyze_code(request.code)

    # 2. GPT ë³´ê³ ì„œ ìƒì„±
    gpt_report = generate_report(request.code, label=bert_result["label"])

    # 3. GPT ë³´ê³ ì„œì—ì„œ ë¼ë²¨ ì¶”ì¶œ
    gpt_label = extract_label_from_report(gpt_report)

    # 4. GPT ë¼ë²¨ì´ ì¡´ì¬í•˜ê³ , CodeBERT ë¼ë²¨ê³¼ ë‹¤ë¥´ë‹¤ë©´ GPT ê²°ê³¼ë¥¼ ë°˜ì˜
    final = resolve_final_label_score(
        bert_label=bert_result["label"],
        gpt_label=gpt_label
    )

    return {
        "prediction": final["msg"],
        "label": final["label"],
        "security_score": final["score"],
        "report": gpt_report,
        "model_reference": bert_result
    }

# API ë¶„ì„ ë³´ê³ ì„œ docx ë‹¤ìš´ë¡œë“œ
@app.post("/report/docx", 
            summary="DOCX í˜•ì‹ì˜ ì·¨ì•½ì  ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ", 
            description="""
            ì…ë ¥ëœ ì†ŒìŠ¤ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ CodeBERTì™€ GPT APIë¥¼ í™œìš©í•´ ë³´ì•ˆ ì·¨ì•½ì ì„ ë¶„ì„í•˜ì—¬
            ì·¨ì•½ì  ì¢…ë¥˜, ì ìˆ˜, ì„¤ëª…, ê³µê²© ì‹œë‚˜ë¦¬ì˜¤, ë³´ì™„ ë°©ì•ˆì´ í¬í•¨ëœ ë¶„ì„ ë³´ê³ ì„œë¥¼
            Word íŒŒì¼ í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            """
)
def download_docx(request: CodeRequest):
    # 1. ëª¨ë¸ ì˜ˆì¸¡ ë° ë¦¬í¬íŠ¸ ìƒì„±
    bert_result = analyze_code(request.code)
    gpt_report = generate_report(request.code, label=bert_result["label"])
    gpt_label = extract_label_from_report(gpt_report)

    final = resolve_final_label_score(
        bert_label=bert_result["label"],
        gpt_label=gpt_label
    )
    
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")

    # 2. ë¬¸ì„œ ê°ì²´ ìƒì„±
    doc = Document()
    doc.add_heading("AI ê¸°ë°˜ ë³´ì•ˆ ë¶„ì„ ë¦¬í¬íŠ¸", 0)
    doc.add_paragraph(f"ë¶„ì„ ì¼ì‹œ: {timestamp}")
    doc.add_paragraph(f"ì˜ˆì¸¡ëœ ì·¨ì•½ì  ë¼ë²¨: {final['label']}")
    doc.add_paragraph(f"ë³´ì•ˆ ì ìˆ˜: {final['score']}")
    doc.add_paragraph(f"ë¶„ì„ ìš”ì•½ ë©”ì‹œì§€: {final['msg']}")
    doc.add_paragraph("ìƒì„¸ ë³´ì•ˆ ë¦¬í¬íŠ¸:")
    doc.add_paragraph(gpt_report)

    # 3. íŒŒì¼ ì €ì¥
    filename = f"report_{uuid.uuid4().hex[:8]}.docx"
    doc.save(filename)

    return FileResponse(filename, media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document", filename="Security_Report.docx")