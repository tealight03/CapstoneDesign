import os
import re
from fastapi import FastAPI
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F
from openai import OpenAI

# FastAPI ì•± ìƒì„±
app = FastAPI()

# ì…ë ¥ ìŠ¤í‚¤ë§ˆ
class CodeRequest(BaseModel):
    code: str

# ëª¨ë¸ ê²½ë¡œë¥¼ Hugging Face ê²½ë¡œë¡œ ì„¤ì •
model_path = "davin0706/codebert-finetuned-v5"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)

# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

# âœ… ì ìˆ˜ ë§¤í•‘
score_map = {
    0: {"label": "SQL_Injection", "score": 30, "msg": "âš ï¸ SQL Injection ì·¨ì•½ì  ê°ì§€"},
    1: {"label": "Hardcoded_Password", "score": 30, "msg": "âš ï¸ Hardcoded Password ê°ì§€"},
    2: {"label": "XSS", "score": 30, "msg": "âš ï¸ XSS ì·¨ì•½ì  ê°ì§€"},
    3: {"label": "Safe_Code", "score": 100, "msg": "âœ… ì™„ì „í•œ ë°©ì–´ ì½”ë“œ (Safe Code)"},
    4: {"label": "Other", "score": 70, "msg": "âš ï¸ ì ì¬ì  ì·¨ì•½ì ì´ ìˆëŠ” ì½”ë“œ (Other)"}
}

# âœ… ë³´ì•ˆ ë¶„ì„ í•¨ìˆ˜
def analyze_code(code_snippet: str):
    inputs = tokenizer(code_snippet, return_tensors="pt", truncation=True, padding="max_length", max_length=128)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = F.softmax(logits, dim=1)[0]
        predicted = torch.argmax(probs).item()

        # Safe vs Other í›„ì²˜ë¦¬
        if predicted == 3:
            if probs[4].item() > 0.3 and probs[3].item() < 0.7:
                predicted = 4

    return {
        "prediction": score_map[predicted]["msg"],
        "label": score_map[predicted]["label"],
        "security_score": score_map[predicted]["score"]
    }

# âœ… GPT ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜
def generate_report(code_snippet: str, label: str) -> str:
    prompt = f"""
ë‹¹ì‹ ì€ ë³´ì•ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ ì†ŒìŠ¤ ì½”ë“œì—ì„œ ê°ì§€ëœ ì·¨ì•½ì ì€ **'{label}'** ì…ë‹ˆë‹¤.

[ì·¨ì•½ ì½”ë“œ]
{code_snippet.rstrip()}


ğŸ“Œ **1. ì·¨ì•½ì  ì„¤ëª…**
í•´ë‹¹ ì·¨ì•½ì ì´ ë°œìƒí•œ ì´ìœ ì™€ ì½”ë“œ êµ¬ì¡°ìƒ ë¬¸ì œì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ğŸ’£ **2. ê³µê²© ì‹œë‚˜ë¦¬ì˜¤**
ê³µê²©ìê°€ í•´ë‹¹ ì½”ë“œë¥¼ ì–´ë–»ê²Œ ì•…ìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ğŸ›  **3. ë³´ì™„ ë°©ë²• ë° ê°œì„ ëœ ì½”ë“œ ì˜ˆì‹œ**
ë³´ì™„ ë°©ë²•ì„ ì„¤ëª…í•˜ê³ , ë³´ì™„ëœ ì½”ë“œ ì˜ˆì‹œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.

âœ… **4. ìš”ì•½ëœ ë³´ì•ˆ ê¶Œê³ ì‚¬í•­**
ìš”ì•½ëœ ê¶Œê³ ì‚¬í•­ì„ **ë¦¬ìŠ¤íŠ¸ í˜•ì‹**ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

---

ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ğŸ“„ **ë³´ì•ˆ ë¶„ì„ ë¦¬í¬íŠ¸**

---
"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant for code security analysis."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
        max_tokens=1200
    )
    return response.choices[0].message.content

# GPT API ê²°ê³¼ì—ì„œ label ì¶”ì¶œ
def extract_label_from_report(report: str) -> str:
    try:
        match = re.search(r"ì·¨ì•½ì (?:ì€|ì´)?\s+\*\*['\"]?(\w+)['\"]?\*\*", report)
        if match:
            candidate = match.group(1)
            if candidate == "Safe_Code":
                for item in score_map.values():
                    if item["label"] != "Safe_Code" and item["label"] in report:
                        return item["label"]
            return candidate

        for item in score_map.values():
            if item["label"] in report:
                return item["label"]
    except Exception as e:
        print(f"âš ï¸ extract_label_from_report ì˜ˆì™¸ ë°œìƒ: {e}")
        
    return None

# âœ… API ì—”ë“œí¬ì¸íŠ¸
@app.post("/analyze")
def analyze(request: CodeRequest):
    # 1. CodeBERT ì˜ˆì¸¡ (ë³´ì¡° ì •ë³´)
    bert_result = analyze_code(request.code)

    # 2. GPT ë¦¬í¬íŠ¸ ìƒì„±
    gpt_report = generate_report(request.code, label=bert_result["label"])

    # 3. GPT ë¦¬í¬íŠ¸ ê¸°ë°˜ ë¼ë²¨ ì¶”ì¶œ
    gpt_label = extract_label_from_report(gpt_report)

    # 4. GPT íŒë‹¨ì´ ìœ íš¨í•  ê²½ìš° ìµœì¢… ê²°ê³¼ë¡œ ì‚¬ìš©
    if gpt_label and gpt_label in [v["label"] for v in score_map.values()]:
        final = next(v for v in score_map.values() if v["label"] == gpt_label)
    else:
        # fallback: CodeBERT ê²°ê³¼ ì‚¬ìš©
        final = {
            "label": bert_result["label"],
            "score": bert_result["security_score"],
            "msg": bert_result["prediction"]
        }

    return {
        "prediction": final["msg"],
        "label": final["label"],
        "security_score": final["score"],
        "report": gpt_report,
        "model_reference": bert_result  # ì°¸ê³ ìš©ìœ¼ë¡œ CodeBERT ê²°ê³¼ë„ ê°™ì´ ë¦¬í„´
    }