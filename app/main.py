import os
import re
from fastapi import FastAPI
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F
from openai import OpenAI

# FastAPI ì•± ìƒì„±
app = FastAPI()

# ì…ë ¥ ìŠ¤í‚¤ë§ˆ
class CodeRequest(BaseModel):
    code: str

# ëª¨ë¸ ê²½ë¡œë¥¼ Hugging Face ê²½ë¡œë¡œ ì„¤ì •
model_path = "davin0706/codebert-finetuned-v5"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)

# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

# âœ… ì ìˆ˜ ë§¤í•‘
score_map = {
    0: {"label": "SQL_Injection", "score": 30, "msg": "âš ï¸ SQL Injection ì·¨ì•½ì  ê°ì§€"},
    1: {"label": "Hardcoded_Password", "score": 30, "msg": "âš ï¸ Hardcoded Password ê°ì§€"},
    2: {"label": "XSS", "score": 30, "msg": "âš ï¸ XSS ì·¨ì•½ì  ê°ì§€"},
    3: {"label": "Safe_Code", "score": 100, "msg": "âœ… ì™„ì „í•œ ë°©ì–´ ì½”ë“œ (Safe Code)"},
    4: {"label": "Other", "score": 70, "msg": "âš ï¸ ì ì¬ì  ì·¨ì•½ì ì´ ìˆëŠ” ì½”ë“œ (Other)"}
}

# âœ… ë³´ì•ˆ ë¶„ì„ í•¨ìˆ˜
def analyze_code(code_snippet: str):
    inputs = tokenizer(code_snippet, return_tensors="pt", truncation=True, padding="max_length", max_length=128)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = F.softmax(logits, dim=1)[0]
        predicted = torch.argmax(probs).item()

        # Safe vs Other í›„ì²˜ë¦¬
        if predicted == 3:
            if probs[4].item() > 0.3 and probs[3].item() < 0.7:
                predicted = 4

    return {
        "prediction": score_map[predicted]["msg"],
        "label": score_map[predicted]["label"],
        "security_score": score_map[predicted]["score"]
    }

# âœ… GPT ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜
def generate_report(code_snippet: str, label: str) -> str:
    prompt = f"""
ë‹¹ì‹ ì€ ë³´ì•ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ ì†ŒìŠ¤ ì½”ë“œì—ì„œ ê°ì§€ëœ ì·¨ì•½ì ì€ **'{label}'** ì…ë‹ˆë‹¤.

[ì·¨ì•½ ì½”ë“œ]
{code_snippet.rstrip()}


ğŸ“Œ **1. ì·¨ì•½ì  ì„¤ëª…**
í•´ë‹¹ ì·¨ì•½ì ì´ ë°œìƒí•œ ì´ìœ ì™€ ì½”ë“œ êµ¬ì¡°ìƒ ë¬¸ì œì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ğŸ’£ **2. ê³µê²© ì‹œë‚˜ë¦¬ì˜¤**
ê³µê²©ìê°€ í•´ë‹¹ ì½”ë“œë¥¼ ì–´ë–»ê²Œ ì•…ìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ğŸ›  **3. ë³´ì™„ ë°©ë²• ë° ê°œì„ ëœ ì½”ë“œ ì˜ˆì‹œ**
ë³´ì™„ ë°©ë²•ì„ ì„¤ëª…í•˜ê³ , ë³´ì™„ëœ ì½”ë“œ ì˜ˆì‹œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.

âœ… **4. ìš”ì•½ëœ ë³´ì•ˆ ê¶Œê³ ì‚¬í•­**
ìš”ì•½ëœ ê¶Œê³ ì‚¬í•­ì„ **ë¦¬ìŠ¤íŠ¸ í˜•ì‹**ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

---

ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ğŸ“„ **ë³´ì•ˆ ë¶„ì„ ë¦¬í¬íŠ¸**

---
"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant for code security analysis."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
        max_tokens=1200
    )
    return response.choices[0].message.content

# GPT API ê²°ê³¼ì—ì„œ label ì¶”ì¶œ
def extract_label_from_report(report: str) -> str:
    try:
        # ì •ê·œì‹ìœ¼ë¡œ ì·¨ì•½ì  ë¼ë²¨ ì¶”ì¶œ ì‹œë„
        match = re.search(r"ì·¨ì•½ì (?:ì€|ì´)?[^ê°€-í£]{0,5}\*\*['\"]?(.+?)['\"]?\*\*", report)
        if match:
            candidate = match.group(1).strip().replace(" ", "_")
            print(f"ğŸ” [ì •ê·œì‹ ë§¤ì¹­] ì¶”ì¶œëœ candidate: '{candidate}'")

            # ì•ˆì „í•œ ì½”ë“œë¡œ íŒëª…ë˜ì—ˆì„ ê²½ìš°
            if candidate == "Safe_Code":
                for item in score_map.values():
                    if item["label"] != "Safe_Code" and item["label"] in report:
                        print(f"âš ï¸ Safe_Code ì˜¤íƒ ê°ì§€, ëŒ€ì²´ ë¼ë²¨ ì‚¬ìš©: '{item['label']}'")
                        return item["label"]
            print(f"âœ… ìµœì¢… ì„ íƒëœ ë¼ë²¨ (ì •ê·œì‹ ê¸°ì¤€): '{candidate}'")
            return candidate

        # fallback: ì •ê·œì‹ ì‹¤íŒ¨ ì‹œ, ë³¸ë¬¸ ë‚´ì—ì„œ ìˆ˜ë™ íƒìƒ‰
        for item in score_map.values():
            if item["label"] in report:
                print(f"ğŸ” [ë³¸ë¬¸ íƒìƒ‰] '{item['label']}' ë¼ë²¨ì´ ë³´ê³ ì„œì— ì§ì ‘ í¬í•¨ë˜ì–´ ìˆìŒ")
                return item["label"]

    except Exception as e:
        print(f"âš ï¸ extract_label_from_report ì˜ˆì™¸ ë°œìƒ: {e}")
    
    print("âŒ ë¼ë²¨ ì¶”ì¶œ ì‹¤íŒ¨: None ë°˜í™˜")
    return None

# âœ… API ì—”ë“œí¬ì¸íŠ¸
@app.post("/analyze")
def analyze(request: CodeRequest):
    # 1. CodeBERT ê²°ê³¼
    bert_result = analyze_code(request.code)

    # 2. GPT ë³´ê³ ì„œ ìƒì„±
    gpt_report = generate_report(request.code, label=bert_result["label"])

    # 3. GPT ë³´ê³ ì„œì—ì„œ ë¼ë²¨ ì¶”ì¶œ
    gpt_label = extract_label_from_report(gpt_report)

    # 4. GPT ë¼ë²¨ì´ ì¡´ì¬í•˜ê³ , CodeBERT ë¼ë²¨ê³¼ ë‹¤ë¥´ë‹¤ë©´ GPT ê²°ê³¼ë¥¼ ë°˜ì˜
    if gpt_label and gpt_label != bert_result["label"]:
        matched_entry = None

        # ë¼ë²¨ ì¤‘ GPT ë³´ê³ ì„œì˜ ë¼ë²¨ê³¼ ì¼ì¹˜í•˜ëŠ” ê²ƒì´ ìˆëŠ”ì§€ í™•ì¸
        for entry in score_map.values():
            label_key = entry["label"].lower()
            if label_key == gpt_label.lower():
                matched_entry = entry
                break
        # ì¼ì¹˜í•˜ëŠ” ë¼ë²¨ì´ ìˆë‹¤ë©´ GPT ë³´ê³ ì„œë¡œ ìˆ˜ì •
        if matched_entry:
            final = matched_entry
        else:
            # fallback: CodeBERT ê²°ê³¼ ì‚¬ìš©
            final = {
                "label": bert_result["label"],
                "score": bert_result["security_score"],
                "msg": bert_result["prediction"]
            }
    else:
        # GPT ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ê°™ì„ ê²½ìš°, CodeBERT ê·¸ëŒ€ë¡œ ì‚¬ìš©
        final = {
            "label": bert_result["label"],
            "score": bert_result["security_score"],
            "msg": bert_result["prediction"]
        }

    return {
        "prediction": final["msg"],
        "label": final["label"],
        "security_score": final["score"],
        "report": gpt_report,
        "model_reference": bert_result
    }