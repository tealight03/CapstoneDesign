import os
import re
import torch
import uuid
import datetime
import torch.nn.functional as F
from markdown import markdown
from weasyprint import HTML
from openai import OpenAI
from fastapi import FastAPI, Body
from pydantic import BaseModel, Field
from docx import Document
from fastapi.responses import FileResponse
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# FastAPI ì•± ìƒì„±(Swagger ë¬¸ì„œ ì •ë³´ í¬í•¨í•¨)
app = FastAPI(
    title = 'AI ê¸°ë°˜ ì½”ë“œ ë³´ì•ˆ ë¶„ì„ê¸° API',
    description = "CodeBERTì™€ GPT APIë¥¼ í™œìš©í•´ ì½”ë“œì˜ ë³´ì•ˆ ì·¨ì•½ì ì„ ìë™ íƒì§€í•˜ê³ , ë³´ì•ˆ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” APIì…ë‹ˆë‹¤.",
    version = "1.0.0",
    contact = {
        "email": "davin0706@gmail.com",
        "url": "https://github.com/tealight03/CapstoneDesign"
    }
)

# ì…ë ¥ ìŠ¤í‚¤ë§ˆ
class CodeRequest(BaseModel):
    code: str = Field(
        ...,
        description = "ë³´ì•ˆ ë¶„ì„í•  ì†ŒìŠ¤ ì½”ë“œ (Python)",
        example = "user_input = input('Enter ID: ')\nsql = 'SELECT * FROM users WHERE id = ' + user_input"
    )
    
# ì‘ë‹µ ìŠ¤í‚¤ë§ˆ
class AnalyzeResponse(BaseModel):
    prediction: str = Field(..., description="ë¶„ì„ ê²°ê³¼ ë©”ì‹œì§€")
    label: str = Field(..., description="ì˜ˆì¸¡ëœ ë³´ì•ˆ ì·¨ì•½ì  ë¼ë²¨ (ì˜ˆ: SQL_Injection, Safe_Code ë“±)")
    security_score: int = Field(..., description="0~100 ì‚¬ì´ì˜ ë³´ì•ˆ ì ìˆ˜ (ë‚®ì„ìˆ˜ë¡ ì·¨ì•½í•¨)")
    report: str = Field(..., description="GPT APIê°€ ì‘ì„±í•œ ë³´ì•ˆ ë¶„ì„ ë³´ê³ ì„œ")
    model_reference: dict = Field(..., description="CodeBERT ëª¨ë¸ì˜ ì›ë˜ ì˜ˆì¸¡ ê²°ê³¼")

# ëª¨ë¸ ê²½ë¡œë¥¼ Hugging Face ê²½ë¡œë¡œ ì„¤ì •
model_path = "davin0706/codebert-finetuned-v5"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)

# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

# âœ… ì ìˆ˜ ë§¤í•‘
score_map = {
    0: {"label": "SQL_Injection", "score": 30, "msg": "âš ï¸ SQL Injection ì·¨ì•½ì  ê°ì§€"},
    1: {"label": "Hardcoded_Password", "score": 30, "msg": "âš ï¸ Hardcoded Password ê°ì§€"},
    2: {"label": "XSS", "score": 30, "msg": "âš ï¸ XSS ì·¨ì•½ì  ê°ì§€"},
    3: {"label": "Safe_Code", "score": 100, "msg": "âœ… ì™„ì „í•œ ë°©ì–´ ì½”ë“œ (Safe Code)"},
    4: {"label": "Other", "score": 70, "msg": "âš ï¸ ì ì¬ì  ì·¨ì•½ì ì´ ìˆëŠ” ì½”ë“œ (Other)"}
}

# âœ… ë³´ì•ˆ ë¶„ì„ í•¨ìˆ˜
def analyze_code(code_snippet: str):
    inputs = tokenizer(code_snippet, return_tensors="pt", truncation=True, padding="max_length", max_length=128)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = F.softmax(logits, dim=1)[0]
        predicted = torch.argmax(probs).item()

        # Safe vs Other í›„ì²˜ë¦¬
        if predicted == 3:
            if probs[4].item() > 0.3 and probs[3].item() < 0.7:
                predicted = 4

    return {
        "prediction": score_map[predicted]["msg"],
        "label": score_map[predicted]["label"],
        "security_score": score_map[predicted]["score"]
    }

# âœ… GPT ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜
def generate_report(code_snippet: str) -> str:
    prompt = f"""
ë‹¹ì‹ ì€ ë³´ì•ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ ì†ŒìŠ¤ ì½”ë“œë¥¼ ì •ë°€íˆ ë¶„ì„í•˜ì—¬ ë³´ì•ˆ ì·¨ì•½ì ì„ ì§„ë‹¨í•˜ê³ , ì•„ë˜ í˜•ì‹ì— ë”°ë¼ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

[ì·¨ì•½ ì½”ë“œ]
{code_snippet.rstrip()}


ğŸ“Œ **1. ì·¨ì•½ì  ì„¤ëª…**
í•´ë‹¹ ì·¨ì•½ì ì´ ë°œìƒí•œ ì´ìœ ì™€ ì½”ë“œ êµ¬ì¡°ìƒ ë¬¸ì œì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ğŸ’£ **2. ê³µê²© ì‹œë‚˜ë¦¬ì˜¤**
ê³µê²©ìê°€ í•´ë‹¹ ì½”ë“œë¥¼ ì–´ë–»ê²Œ ì•…ìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ğŸ›  **3. ë³´ì™„ ë°©ë²• ë° ê°œì„ ëœ ì½”ë“œ ì˜ˆì‹œ**
ë³´ì™„ ë°©ë²•ì„ ì„¤ëª…í•˜ê³ , ë³´ì™„ëœ ì½”ë“œ ì˜ˆì‹œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.

âœ… **4. ìš”ì•½ëœ ë³´ì•ˆ ê¶Œê³ ì‚¬í•­**
ìš”ì•½ëœ ê¶Œê³ ì‚¬í•­ì„ **ë¦¬ìŠ¤íŠ¸ í˜•ì‹**ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

---

ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ğŸ“„ **ë³´ì•ˆ ë¶„ì„ ë¦¬í¬íŠ¸**

---
"""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant for code security analysis."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
        max_tokens=1200
    )
    return response.choices[0].message.content

# GPT API ê²°ê³¼ì—ì„œ label ì¶”ì¶œ
def extract_label_from_report(report: str) -> str:
    try:
        # ì •ê·œì‹ìœ¼ë¡œ ì·¨ì•½ì  ë¼ë²¨ ì¶”ì¶œ ì‹œë„
        match = re.search(r"ì·¨ì•½ì (?:ì€|ì´)?[^ê°€-í£]{0,5}\*\*['\"]?(.+?)['\"]?\*\*", report)
        if match:
            candidate = match.group(1).strip().replace(" ", "_")
            print(f"ğŸ” [ì •ê·œì‹ ë§¤ì¹­] ì¶”ì¶œëœ candidate: '{candidate}'")

            # ì•ˆì „í•œ ì½”ë“œë¡œ íŒëª…ë˜ì—ˆì„ ê²½ìš°
            if candidate == "Safe_Code":
                for item in score_map.values():
                    if item["label"] != "Safe_Code" and item["label"] in report:
                        print(f"âš ï¸ Safe_Code ì˜¤íƒ ê°ì§€, ëŒ€ì²´ ë¼ë²¨ ì‚¬ìš©: '{item['label']}'")
                        return item["label"]
            print(f"âœ… ìµœì¢… ì„ íƒëœ ë¼ë²¨ (ì •ê·œì‹ ê¸°ì¤€): '{candidate}'")
            return candidate

        # fallback: ì •ê·œì‹ ì‹¤íŒ¨ ì‹œ, ë³¸ë¬¸ ë‚´ì—ì„œ ìˆ˜ë™ íƒìƒ‰
        for item in score_map.values():
            if item["label"] in report:
                print(f"ğŸ” [ë³¸ë¬¸ íƒìƒ‰] '{item['label']}' ë¼ë²¨ì´ ë³´ê³ ì„œì— ì§ì ‘ í¬í•¨ë˜ì–´ ìˆìŒ")
                return item["label"]

    except Exception as e:
        print(f"âš ï¸ extract_label_from_report ì˜ˆì™¸ ë°œìƒ: {e}")
    
    print("âŒ ë¼ë²¨ ì¶”ì¶œ ì‹¤íŒ¨: None ë°˜í™˜")
    return None

# / ë¥¼ ì„œë²„ í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ë¡œ í™œìš©
@app.get("/", summary="API ì„œë²„ í—¬ìŠ¤ ì²´í¬")
def root():
    return {"message": "ğŸš€ Code Security Analyzer is running!"}

# âœ… API ì—”ë“œí¬ì¸íŠ¸
@app.post("/analyze", summary = "ì†ŒìŠ¤ ì½”ë“œ ë³´ì•ˆ ì·¨ì•½ì  ë¶„ì„", response_model = AnalyzeResponse)
def analyze(request: CodeRequest = Body(...)):
    # 1. CodeBERT ê²°ê³¼
    bert_result = analyze_code(request.code)

    # 2. GPT ë³´ê³ ì„œ ìƒì„±
    gpt_report = generate_report(request.code)

    # 3. GPT ë³´ê³ ì„œì—ì„œ ë¼ë²¨ ì¶”ì¶œ
    gpt_label = extract_label_from_report(gpt_report)

    # 4. GPT ë¼ë²¨ì´ ì¡´ì¬í•˜ê³ , CodeBERT ë¼ë²¨ê³¼ ë‹¤ë¥´ë‹¤ë©´ GPT ê²°ê³¼ë¥¼ ë°˜ì˜
    if gpt_label and gpt_label != bert_result["label"]:
        matched_entry = None

        # ë¼ë²¨ ì¤‘ GPT ë³´ê³ ì„œì˜ ë¼ë²¨ê³¼ ì¼ì¹˜í•˜ëŠ” ê²ƒì´ ìˆëŠ”ì§€ í™•ì¸
        for entry in score_map.values():
            label_key = entry["label"].lower()
            if label_key == gpt_label.lower():
                matched_entry = entry
                break
        # ì¼ì¹˜í•˜ëŠ” ë¼ë²¨ì´ ìˆë‹¤ë©´ GPT ë³´ê³ ì„œë¡œ ìˆ˜ì •
        if matched_entry:
            final = matched_entry
        else:
            # fallback: CodeBERT ê²°ê³¼ ì‚¬ìš©
            final = {
                "label": bert_result["label"],
                "score": bert_result["security_score"],
                "msg": bert_result["prediction"]
            }
    else:
        # GPT ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ê°™ì„ ê²½ìš°, CodeBERT ê·¸ëŒ€ë¡œ ì‚¬ìš©
        final = {
            "label": bert_result["label"],
            "score": bert_result["security_score"],
            "msg": bert_result["prediction"]
        }

    return {
        "prediction": final["msg"],
        "label": final["label"],
        "security_score": final["score"],
        "report": gpt_report,
        "model_reference": bert_result
    }

# API ë¶„ì„ ë³´ê³ ì„œ docx ë‹¤ìš´ë¡œë“œ
@app.post("/report/docx", 
            summary="DOCX í˜•ì‹ì˜ ì·¨ì•½ì  ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ", 
            description="""
            ì…ë ¥ëœ ì†ŒìŠ¤ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ CodeBERTì™€ GPT APIë¥¼ í™œìš©í•´ ë³´ì•ˆ ì·¨ì•½ì ì„ ë¶„ì„í•˜ì—¬
            ì·¨ì•½ì  ì¢…ë¥˜, ì ìˆ˜, ì„¤ëª…, ê³µê²© ì‹œë‚˜ë¦¬ì˜¤, ë³´ì™„ ë°©ì•ˆì´ í¬í•¨ëœ ë¶„ì„ ë³´ê³ ì„œë¥¼
            Word íŒŒì¼ í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            """
)
def download_docx(request: CodeRequest):
    # 1. ëª¨ë¸ ì˜ˆì¸¡ ë° ë¦¬í¬íŠ¸ ìƒì„±
    bert_result = analyze_code(request.code)
    gpt_report = generate_report(request.code, bert_result["label"])
    gpt_label = extract_label_from_report(gpt_report)

    final_label = gpt_label or bert_result["label"]
    final_score = bert_result["security_score"]
    final_msg = bert_result["prediction"]
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")

    # 2. ë¬¸ì„œ ê°ì²´ ìƒì„±
    doc = Document()
    doc.add_heading("AI ê¸°ë°˜ ë³´ì•ˆ ë¶„ì„ ë¦¬í¬íŠ¸", 0)
    doc.add_paragraph(f"ë¶„ì„ ì¼ì‹œ: {timestamp}")
    doc.add_paragraph(f"ì˜ˆì¸¡ëœ ì·¨ì•½ì  ë¼ë²¨: {final_label}")
    doc.add_paragraph(f"ë³´ì•ˆ ì ìˆ˜: {final_score}")
    doc.add_paragraph(f"ë¶„ì„ ìš”ì•½ ë©”ì‹œì§€: {final_msg}")
    doc.add_paragraph("ìƒì„¸ ë³´ì•ˆ ë¦¬í¬íŠ¸:")
    doc.add_paragraph(gpt_report)

    # 3. íŒŒì¼ ì €ì¥
    filename = f"report_{uuid.uuid4().hex[:8]}.docx"
    doc.save(filename)

    return FileResponse(filename, media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document", filename="Security_Report.docx")