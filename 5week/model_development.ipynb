{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c59634e48d7465ab45d404c7cc7dc8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c3d18a6640342dcbf86f11f106e7ba6",
              "IPY_MODEL_4079dd7a723a4191a9b62f2daf8701da",
              "IPY_MODEL_9dbab5e84f4a4bb9961778f5e406b441"
            ],
            "layout": "IPY_MODEL_7cf65cdb6ac947acb8aa55fee8e103cf"
          }
        },
        "2c3d18a6640342dcbf86f11f106e7ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_005040f6f6f947d4aecfc1312abd737a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0c932243fe0940a7bc62b5e3083ab9d1",
            "value": "Map:â€‡100%"
          }
        },
        "4079dd7a723a4191a9b62f2daf8701da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbc7d33582a248aa9aeef8dc9efcd796",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d254c362fc7e4e8b90e00b8c5f4d5268",
            "value": 30
          }
        },
        "9dbab5e84f4a4bb9961778f5e406b441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_506397d60e4140ebb5ee081a3c3b5a09",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_54848f94e52543afa1c86c5449406804",
            "value": "â€‡30/30â€‡[00:00&lt;00:00,â€‡376.46â€‡examples/s]"
          }
        },
        "7cf65cdb6ac947acb8aa55fee8e103cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "005040f6f6f947d4aecfc1312abd737a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c932243fe0940a7bc62b5e3083ab9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbc7d33582a248aa9aeef8dc9efcd796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d254c362fc7e4e8b90e00b8c5f4d5268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "506397d60e4140ebb5ee081a3c3b5a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54848f94e52543afa1c86c5449406804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9db7657719941f8af6a32439ad8f23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ae4003c8ca44283a30d97b4038a6916",
              "IPY_MODEL_0bf4f444937349d984d0f00c0c6b5190",
              "IPY_MODEL_f5988e236a7b42268b8f9bd21b17945d"
            ],
            "layout": "IPY_MODEL_a1d9e60a935946098562020b8ca851ac"
          }
        },
        "5ae4003c8ca44283a30d97b4038a6916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb014b145a5b4d1bb7638763621a0422",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f376cc792454498ea60dcf01d23c58b0",
            "value": "Map:â€‡100%"
          }
        },
        "0bf4f444937349d984d0f00c0c6b5190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e9bd6dc6ca545d19575693726e65521",
            "max": 120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62513f6b8e6c47d4aa3a1e36e873a293",
            "value": 120
          }
        },
        "f5988e236a7b42268b8f9bd21b17945d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_492868a2f1b2477fac0c0394c3b9d482",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_962e319a22e3424aa58090a38182ab8f",
            "value": "â€‡120/120â€‡[00:00&lt;00:00,â€‡1046.15â€‡examples/s]"
          }
        },
        "a1d9e60a935946098562020b8ca851ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb014b145a5b4d1bb7638763621a0422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f376cc792454498ea60dcf01d23c58b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e9bd6dc6ca545d19575693726e65521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62513f6b8e6c47d4aa3a1e36e873a293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "492868a2f1b2477fac0c0394c3b9d482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "962e319a22e3424aa58090a38182ab8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# sympy ë²„ì „ì„ transformersì™€ í˜¸í™˜ë˜ëŠ” ì•ˆì •ëœ ë²„ì „ìœ¼ë¡œ ë‹¤ìš´ê·¸ë ˆì´ë“œ\n",
        "!pip install sympy==1.12 --quiet\n",
        "# ëŸ°íƒ€ì„ ì¬ì‹œì‘ í•„ìš” ì—†ì´ ë°”ë¡œ ì‚¬ìš©í•˜ë„ë¡ transformers ì¬ì„¤ì¹˜\n",
        "!pip install transformers --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifnCf7XR8a4O",
        "outputId": "48188130-b7eb-4607-bfb3-114390e3ad8a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/5.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.6/5.7 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.12 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLRD-pW56xp6",
        "outputId": "bf0b357b-6d4b-4c96-f1d3-3cfce2a173a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Google Driveì—ì„œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from google.colab import drive\n",
        "\n",
        "# âœ… Google Drive ë§ˆìš´íŠ¸\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# âœ… ëª¨ë¸ ê²½ë¡œ\n",
        "model_path = \"/content/drive/MyDrive/models/codebert_finetuned_v2\"\n",
        "\n",
        "# âœ… ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "print(\"âœ… Google Driveì—ì„œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ìµœì‹  openai (v1 ì´ìƒ) ë°©ì‹\n",
        "from openai import OpenAI\n",
        "\n",
        "# âš ï¸ íŒŒì¼ ì—…ë¡œë“œí•  ë•ŒëŠ” ìˆ¨ê¸°ê¸°\n",
        "client = OpenAI(api_key=\"GPT-API Key\")\n",
        "\n",
        "def generate_report(code_snippet: str, label: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "ë‹¹ì‹ ì€ ë³´ì•ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "ì•„ë˜ì˜ ì†ŒìŠ¤ ì½”ë“œëŠ” '{label}' ì·¨ì•½ì ì´ ê°ì§€ëœ ì½”ë“œì…ë‹ˆë‹¤.\n",
        "\n",
        "[ì·¨ì•½ ì½”ë“œ]\n",
        "{code_snippet}\n",
        "\n",
        "ì´ ì½”ë“œì— ëŒ€í•´ ë‹¤ìŒ ë‚´ìš©ì„ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n",
        "1. ì·¨ì•½ì  ì„¤ëª… (ì™œ ìœ„í—˜í•œê°€?)\n",
        "2. ê³µê²©ìê°€ ì•…ìš©í•˜ëŠ” ë°©ë²•\n",
        "3. ë³´ì™„ ë°©ë²• (ë³´ì™„ëœ ì½”ë“œ ì˜ˆì‹œ í¬í•¨)\n",
        "4. ìš”ì•½ëœ ë³´ì•ˆ ê¶Œê³ ì‚¬í•­\n",
        "\n",
        "ì „ë¬¸ì ì¸ ë³´ì•ˆ ë¶„ì„ ë³´ê³ ì„œ í˜•íƒœë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant for code security analysis.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=2048\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "qpDszXHi8fgd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# âœ… ë¼ë²¨ ë° ì ìˆ˜ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬\n",
        "score_map = {\n",
        "    0: {\"label\": \"SQL_Injection\", \"score\": 30, \"msg\": \"âš ï¸ SQL Injection ì·¨ì•½ì  ê°ì§€\"},\n",
        "    1: {\"label\": \"Hardcoded_Password\", \"score\": 30, \"msg\": \"âš ï¸ Hardcoded Password ê°ì§€\"},\n",
        "    2: {\"label\": \"XSS\", \"score\": 30, \"msg\": \"âš ï¸ XSS ì·¨ì•½ì  ê°ì§€\"},\n",
        "    3: {\"label\": \"Other\", \"score\": 70, \"msg\": \"âš ï¸ ì ì¬ì  ì·¨ì•½ì ì´ ìˆëŠ” ì½”ë“œ (Other)\"},\n",
        "    4: {\"label\": \"Safe_Code\", \"score\": 100, \"msg\": \"âœ… ì™„ì „í•œ ë°©ì–´ ì½”ë“œ (Safe Code)\"}\n",
        "}\n",
        "\n",
        "def analyze_code(code_snippet):\n",
        "    inputs = tokenizer(\n",
        "        code_snippet,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    # âœ… ëª¨ë¸ê³¼ ì…ë ¥ í…ì„œë¥¼ ë™ì¼í•œ ì¥ì¹˜ë¡œ ì´ë™ (GPU ë˜ëŠ” CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # âœ… ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predicted = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    # âœ… ê²°ê³¼ ë¦¬í„´\n",
        "    result = score_map[predicted]\n",
        "    return {\n",
        "        \"prediction\": result[\"msg\"],\n",
        "        \"label\": result[\"label\"],\n",
        "        \"security_score\": result[\"score\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "b_DJzc7893jD"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5ê°€ì§€ ë ˆì´ë¸” í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ ìƒ˜í”Œ\n",
        "test_cases = [\n",
        "    # 1: SQL Injection\n",
        "    \"\"\"\n",
        "    user_input = request.args.get('username')\n",
        "    query = \"SELECT * FROM users WHERE name = '\" + user_input + \"'\"\n",
        "    \"\"\",\n",
        "\n",
        "    # 2: Hardcoded Password\n",
        "    \"\"\"\n",
        "    password = \"admin123\"\n",
        "    login(user, password)\n",
        "    \"\"\",\n",
        "\n",
        "    # 3: XSS\n",
        "    \"\"\"\n",
        "    @app.route('/search')\n",
        "    def search():\n",
        "        keyword = request.args.get('q')\n",
        "        return \"<p>\" + keyword + \"</p>\"\n",
        "    \"\"\",\n",
        "\n",
        "    # 4: Safe Code\n",
        "    \"\"\"\n",
        "    user_input = request.args.get('username')\n",
        "    query = \"SELECT * FROM users WHERE name = %s\"\n",
        "    cursor.execute(query, (user_input,))\n",
        "    \"\"\",\n",
        "\n",
        "    # 5: Other\n",
        "    \"\"\"\n",
        "    with open(\"log.txt\", \"w\") as f:\n",
        "        f.write(\"User logged in\")\n",
        "    \"\"\"\n",
        "]\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "for idx, code in enumerate(test_cases, start=1):\n",
        "    result = analyze_code(code)\n",
        "    print(f\"[Test Case {idx}] ğŸ” ê²°ê³¼: {result['prediction']} | ğŸ” ì ìˆ˜: {result['security_score']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA6W7axo8iNF",
        "outputId": "7a9eb6e7-0432-4cce-f068-401f5f24126d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Test Case 1] ğŸ” ê²°ê³¼: âš ï¸ SQL Injection ì·¨ì•½ì  ê°ì§€ | ğŸ” ì ìˆ˜: 30\n",
            "[Test Case 2] ğŸ” ê²°ê³¼: âš ï¸ Hardcoded Password ê°ì§€ | ğŸ” ì ìˆ˜: 30\n",
            "[Test Case 3] ğŸ” ê²°ê³¼: âš ï¸ XSS ì·¨ì•½ì  ê°ì§€ | ğŸ” ì ìˆ˜: 30\n",
            "[Test Case 4] ğŸ” ê²°ê³¼: âœ… ì™„ì „í•œ ë°©ì–´ ì½”ë“œ (Safe Code) | ğŸ” ì ìˆ˜: 100\n",
            "[Test Case 5] ğŸ” ê²°ê³¼: âœ… ì™„ì „í•œ ë°©ì–´ ì½”ë“œ (Safe Code) | ğŸ” ì ìˆ˜: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„° ì¶”ê°€ í•™ìŠµìš© íŒŒì¼ ì—…ë¡œë“œ\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ì—…ë¡œë“œí•œ CSV íŒŒì¼ ë¡œë“œ\n",
        "df = pd.read_csv(\"SQL_Injection_Examples.csv\")\n",
        "\n",
        "# í™•ì¸\n",
        "print(\"âœ… CSV ë¡œë“œ ì™„ë£Œ!\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "bdlEUF02AZPO",
        "outputId": "a930eef3-c153-455c-9969-92b151adee34"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1d164637-698e-401c-a5d3-9f56d0dd7685\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1d164637-698e-401c-a5d3-9f56d0dd7685\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving SQL_Injection_Examples.csv to SQL_Injection_Examples (1).csv\n",
            "âœ… CSV ë¡œë“œ ì™„ë£Œ!\n",
            "                                        code_snippet          label\n",
            "0  user_input = request.args.get('username')\\nque...  SQL_Injection\n",
            "1  query = \"SELECT * FROM products WHERE id = \" +...  SQL_Injection\n",
            "2  sql = \"DELETE FROM orders WHERE order_id = \" +...  SQL_Injection\n",
            "3  username = input(\"Username: \")\\nsql = \"SELECT ...  SQL_Injection\n",
            "4  query = \"INSERT INTO logs (message) VALUES ('\"...  SQL_Injection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets\n",
        "!pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MZwm8NQ8iG7",
        "outputId": "ec333264-b1b1-4d39-c836-90ca5bf9896d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# âœ… CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "df = pd.read_csv(\"SQL_Injection_Examples.csv\")\n",
        "\n",
        "# âœ… ë¼ë²¨ ë§¤í•‘\n",
        "label_map = {\n",
        "    \"SQL_Injection\": 0,\n",
        "    \"Hardcoded_Password\": 1,\n",
        "    \"XSS\": 2,\n",
        "    \"Safe_Code\": 3,\n",
        "    \"Other\": 4\n",
        "}\n",
        "df[\"label\"] = df[\"label\"].map(label_map)\n",
        "\n",
        "# âœ… NaN ì œê±°\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# âœ… CodeBERT í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "\n",
        "# âœ… í† í¬ë‚˜ì´ì¦ˆ í•¨ìˆ˜ ì •ì˜\n",
        "def tokenize(example):\n",
        "    tokens = tokenizer(example[\"code_snippet\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    tokens[\"labels\"] = example[\"label\"]\n",
        "    return tokens\n",
        "\n",
        "# âœ… Hugging Face Datasetìœ¼ë¡œ ë³€í™˜ & ì „ì²˜ë¦¬\n",
        "dataset = Dataset.from_pandas(df)\n",
        "tokenized_dataset = dataset.map(tokenize)\n",
        "\n",
        "# âœ… ê¸°ì¡´ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¡œë“œ\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/models/codebert_finetuned_v2\", num_labels=5)\n",
        "\n",
        "# âœ… í•™ìŠµ ì„¤ì •\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./codebert_finetuned_v3\",  # âœ… í•™ìŠµ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# âœ… Trainer ì •ì˜ ë° í•™ìŠµ ì‹¤í–‰\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=tokenized_dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# âœ… ëª¨ë¸ ì €ì¥\n",
        "model.save_pretrained(\"./codebert_finetuned_v3\")\n",
        "tokenizer.save_pretrained(\"./codebert_finetuned_v3\")\n",
        "print(\"âœ… SQL Injection ì˜ˆì œ ì¶”ê°€ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "3c59634e48d7465ab45d404c7cc7dc8d",
            "2c3d18a6640342dcbf86f11f106e7ba6",
            "4079dd7a723a4191a9b62f2daf8701da",
            "9dbab5e84f4a4bb9961778f5e406b441",
            "7cf65cdb6ac947acb8aa55fee8e103cf",
            "005040f6f6f947d4aecfc1312abd737a",
            "0c932243fe0940a7bc62b5e3083ab9d1",
            "fbc7d33582a248aa9aeef8dc9efcd796",
            "d254c362fc7e4e8b90e00b8c5f4d5268",
            "506397d60e4140ebb5ee081a3c3b5a09",
            "54848f94e52543afa1c86c5449406804"
          ]
        },
        "id": "LrxNzIim8iBL",
        "outputId": "ef0259ce-59be-48cb-b44c-96ea7e7f2a00"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c59634e48d7465ab45d404c7cc7dc8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6/6 00:18, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.130895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.088731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.075988</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… SQL Injection ì˜ˆì œ ì¶”ê°€ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„° ì¶”ê°€ í•™ìŠµìš© íŒŒì¼ ì—…ë¡œë“œ\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ì—…ë¡œë“œí•œ CSV íŒŒì¼ ë¡œë“œ\n",
        "df = pd.read_csv(\"ml_examples.csv\")\n",
        "\n",
        "# í™•ì¸\n",
        "print(\"âœ… CSV ë¡œë“œ ì™„ë£Œ!\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "k1Z6U-z7BrF3",
        "outputId": "d919ddc4-7276-45e1-e31d-6743203cce6b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-61547a78-f2dd-427b-9881-7c6f64fb56ff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-61547a78-f2dd-427b-9881-7c6f64fb56ff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ml_examples.csv to ml_examples.csv\n",
            "âœ… CSV ë¡œë“œ ì™„ë£Œ!\n",
            "                                        code_snippet label\n",
            "0  @app.route('/search')\\ndef search():\\n    quer...   XSS\n",
            "1  from flask import Flask, request\\napp = Flask(...   XSS\n",
            "2  @app.route('/comment')\\ndef comment():\\n    us...   XSS\n",
            "3  @app.route('/search')\\ndef search():\\n    quer...   XSS\n",
            "4  from flask import Flask, request\\napp = Flask(...   XSS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# âœ… CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "df = pd.read_csv(\"ml_examples.csv\")\n",
        "\n",
        "# âœ… ë¼ë²¨ ë§¤í•‘\n",
        "label_map = {\n",
        "    \"SQL_Injection\": 0,\n",
        "    \"Hardcoded_Password\": 1,\n",
        "    \"XSS\": 2,\n",
        "    \"Safe_Code\": 3,\n",
        "    \"Other\": 4\n",
        "}\n",
        "df[\"label\"] = df[\"label\"].map(label_map)\n",
        "\n",
        "# âœ… NaN ì œê±°\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# âœ… CodeBERT í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "\n",
        "# âœ… í† í¬ë‚˜ì´ì¦ˆ í•¨ìˆ˜ ì •ì˜\n",
        "def tokenize(example):\n",
        "    tokens = tokenizer(example[\"code_snippet\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    tokens[\"labels\"] = example[\"label\"]\n",
        "    return tokens\n",
        "\n",
        "# âœ… Hugging Face Datasetìœ¼ë¡œ ë³€í™˜ & ì „ì²˜ë¦¬\n",
        "dataset = Dataset.from_pandas(df)\n",
        "tokenized_dataset = dataset.map(tokenize)\n",
        "\n",
        "# âœ… âœ… âœ… Colab ë‚´ë¶€ì— ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œë¡œ ë³€ê²½\n",
        "model_path = \"./codebert_finetuned_v3\"\n",
        "\n",
        "# âœ… ê¸°ì¡´ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¡œë“œ\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=5)\n",
        "\n",
        "# âœ… í•™ìŠµ ì„¤ì •\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./codebert_finetuned_v4\",  # âœ… í•™ìŠµ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# âœ… Trainer ì •ì˜ ë° í•™ìŠµ ì‹¤í–‰\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=tokenized_dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# âœ… ëª¨ë¸ ì €ì¥\n",
        "model.save_pretrained(\"./codebert_finetuned_v4\")\n",
        "tokenizer.save_pretrained(\"./codebert_finetuned_v4\")\n",
        "\n",
        "print(\"âœ… ì·¨ì•½ì  ì˜ˆì œ ì¶”ê°€ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "d9db7657719941f8af6a32439ad8f23d",
            "5ae4003c8ca44283a30d97b4038a6916",
            "0bf4f444937349d984d0f00c0c6b5190",
            "f5988e236a7b42268b8f9bd21b17945d",
            "a1d9e60a935946098562020b8ca851ac",
            "eb014b145a5b4d1bb7638763621a0422",
            "f376cc792454498ea60dcf01d23c58b0",
            "9e9bd6dc6ca545d19575693726e65521",
            "62513f6b8e6c47d4aa3a1e36e873a293",
            "492868a2f1b2477fac0c0394c3b9d482",
            "962e319a22e3424aa58090a38182ab8f"
          ]
        },
        "id": "3vTsxX5OBrDv",
        "outputId": "13ec39a9-f163-47ac-c22f-66a4b9bf063b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/120 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9db7657719941f8af6a32439ad8f23d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24/24 00:34, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.733576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>0.525765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.437857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ì·¨ì•½ì  ì˜ˆì œ ì¶”ê°€ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… í˜„ì¬ í•™ìŠµí•œ ëª¨ë¸ì„ ì €ì¥í•  ê²½ë¡œ ì§€ì •\n",
        "save_path = \"/content/drive/MyDrive/models/codebert_finetuned_v4\"\n",
        "# âœ… ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì €ì¥\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "print(\"âœ… ëª¨ë¸ì´ Google Driveì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVscEUGYBrBb",
        "outputId": "e3d82ad8-dc8e-48e9-e82a-bd04870494c0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ëª¨ë¸ì´ Google Driveì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from google.colab import drive\n",
        "\n",
        "# âœ… Google Drive ë§ˆìš´íŠ¸\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# âœ… ëª¨ë¸ ê²½ë¡œ\n",
        "model_path = \"/content/drive/MyDrive/models/codebert_finetuned_v4\"\n",
        "\n",
        "# âœ… ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "print(\"âœ… Google Driveì—ì„œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njnbs6XvAvcm",
        "outputId": "fa7192a0-7389-46fc-ce19-9b2b1b07778b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… Google Driveì—ì„œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ìµœì‹  openai (v1 ì´ìƒ) ë°©ì‹\n",
        "from openai import OpenAI\n",
        "\n",
        "# âš ï¸ íŒŒì¼ ì—…ë¡œë“œí•  ë•ŒëŠ” ìˆ¨ê¸°ê¸°\n",
        "client = OpenAI(api_key=\"GPT-API Key\")\n",
        "\n",
        "def generate_report(code_snippet: str, label: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "ë‹¹ì‹ ì€ ë³´ì•ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "ì•„ë˜ì˜ ì†ŒìŠ¤ ì½”ë“œëŠ” '{label}' ì·¨ì•½ì ì´ ê°ì§€ëœ ì½”ë“œì…ë‹ˆë‹¤.\n",
        "\n",
        "[ì·¨ì•½ ì½”ë“œ]\n",
        "{code_snippet}\n",
        "\n",
        "ì´ ì½”ë“œì— ëŒ€í•´ ë‹¤ìŒ ë‚´ìš©ì„ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n",
        "1. ì·¨ì•½ì  ì„¤ëª… (ì™œ ìœ„í—˜í•œê°€?)\n",
        "2. ê³µê²©ìê°€ ì•…ìš©í•˜ëŠ” ë°©ë²•\n",
        "3. ë³´ì™„ ë°©ë²• (ë³´ì™„ëœ ì½”ë“œ ì˜ˆì‹œ í¬í•¨)\n",
        "4. ìš”ì•½ëœ ë³´ì•ˆ ê¶Œê³ ì‚¬í•­\n",
        "\n",
        "ì „ë¬¸ì ì¸ ë³´ì•ˆ ë¶„ì„ ë³´ê³ ì„œ í˜•íƒœë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant for code security analysis.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=2048\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "Uf4OlYgipI6G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# âœ… ë¼ë²¨ ë° ì ìˆ˜ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬\n",
        "score_map = {\n",
        "    0: {\"label\": \"SQL_Injection\", \"score\": 30, \"msg\": \"âš ï¸ SQL Injection ì·¨ì•½ì  ê°ì§€\"},\n",
        "    1: {\"label\": \"Hardcoded_Password\", \"score\": 30, \"msg\": \"âš ï¸ Hardcoded Password ê°ì§€\"},\n",
        "    2: {\"label\": \"XSS\", \"score\": 30, \"msg\": \"âš ï¸ XSS ì·¨ì•½ì  ê°ì§€\"},\n",
        "    3: {\"label\": \"Safe_Code\", \"score\": 100, \"msg\": \"âœ… ì™„ì „í•œ ë°©ì–´ ì½”ë“œ (Safe Code)\"},\n",
        "    4: {\"label\": \"Other\", \"score\": 70, \"msg\": \"âš ï¸ ì ì¬ì  ì·¨ì•½ì ì´ ìˆëŠ” ì½”ë“œ (Other)\"}\n",
        "}\n",
        "\n",
        "def analyze_code(code_snippet):\n",
        "    inputs = tokenizer(code_snippet, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = F.softmax(logits, dim=1)[0]  # í™•ë¥ ë¡œ ë³€í™˜\n",
        "        predicted = torch.argmax(probs).item()\n",
        "\n",
        "        # í›„ì²˜ë¦¬ ë¡œì§: Safe_Code vs Other ì„¸ë¶„í™”\n",
        "        if predicted == 3:  # Safe_Codeë¡œ ì˜ˆì¸¡ëì„ ë•Œë§Œ ê²€ì‚¬\n",
        "            safe_prob = probs[3].item()\n",
        "            other_prob = probs[4].item()\n",
        "            if other_prob > 0.3 and safe_prob < 0.7:\n",
        "                predicted = 4  # í™•ì‹ ì´ ë¶€ì¡±í•˜ë©´ Otherë¡œ íŒë‹¨\n",
        "\n",
        "    return {\n",
        "        \"prediction\": score_map[predicted][\"msg\"],\n",
        "        \"label\": score_map[predicted][\"label\"],\n",
        "        \"security_score\": score_map[predicted][\"score\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "MzguPy6FpIy6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    # 1: SQL Injection\n",
        "    \"\"\"\n",
        "    user_input = request.args.get('username')\n",
        "    query = \"SELECT * FROM users WHERE name = '\" + user_input + \"'\"\n",
        "    \"\"\",\n",
        "\n",
        "    # 2: Hardcoded Password\n",
        "    \"\"\"\n",
        "    password = \"admin123\"\n",
        "    login(user, password)\n",
        "    \"\"\",\n",
        "\n",
        "    # 3: XSS\n",
        "    \"\"\"\n",
        "    @app.route('/search')\n",
        "    def search():\n",
        "        keyword = request.args.get('q')\n",
        "        return \"<p>\" + keyword + \"</p>\"\n",
        "    \"\"\",\n",
        "\n",
        "    # 4: Safe Code\n",
        "    \"\"\"\n",
        "    user_input = request.args.get('username')\n",
        "    query = \"SELECT * FROM users WHERE name = %s\"\n",
        "    cursor.execute(query, (user_input,))\n",
        "    \"\"\",\n",
        "\n",
        "    # 5: ë¡œê·¸ ê¸°ë¡ (Other)\n",
        "    \"\"\"\n",
        "    with open(\"log.txt\", \"w\") as f:\n",
        "        f.write(\"User logged in\")\n",
        "    \"\"\"\n",
        "]\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "for idx, code in enumerate(test_cases, start=1):\n",
        "    result = analyze_code(code)\n",
        "    print(f\"[Test Case {idx}] ğŸ” ê²°ê³¼: {result['prediction']} | ğŸ” ì ìˆ˜: {result['security_score']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBy5wDA_pIw6",
        "outputId": "f8e45724-62d4-4dcb-802d-636f89f1afb0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Test Case 1] ğŸ” ê²°ê³¼: âš ï¸ SQL Injection ì·¨ì•½ì  ê°ì§€ | ğŸ” ì ìˆ˜: 30\n",
            "[Test Case 2] ğŸ” ê²°ê³¼: âš ï¸ Hardcoded Password ê°ì§€ | ğŸ” ì ìˆ˜: 30\n",
            "[Test Case 3] ğŸ” ê²°ê³¼: âš ï¸ XSS ì·¨ì•½ì  ê°ì§€ | ğŸ” ì ìˆ˜: 30\n",
            "[Test Case 4] ğŸ” ê²°ê³¼: âœ… ì™„ì „í•œ ë°©ì–´ ì½”ë“œ (Safe Code) | ğŸ” ì ìˆ˜: 100\n",
            "[Test Case 5] ğŸ” ê²°ê³¼: âš ï¸ ì ì¬ì  ì·¨ì•½ì ì´ ìˆëŠ” ì½”ë“œ (Other) | ğŸ” ì ìˆ˜: 70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ìµœì‹  openai (v1 ì´ìƒ) ë°©ì‹\n",
        "from openai import OpenAI\n",
        "\n",
        "# âš ï¸ íŒŒì¼ ì—…ë¡œë“œí•  ë•ŒëŠ” ìˆ¨ê¸°ê¸°\n",
        "client = OpenAI(api_key=\"GPT-API Key\")\n",
        "\n",
        "# âœ… GPT ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜\n",
        "def generate_report(code_snippet: str, label: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "ë‹¹ì‹ ì€ ë³´ì•ˆ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "ì•„ë˜ì˜ ì†ŒìŠ¤ ì½”ë“œì—ì„œ ê°ì§€ëœ ì·¨ì•½ì ì€ **'{label}'** ì…ë‹ˆë‹¤.\n",
        "\n",
        "[ì·¨ì•½ ì½”ë“œ]\n",
        "{code_snippet.rstrip()}\n",
        "\n",
        "\n",
        "ğŸ“Œ **1. ì·¨ì•½ì  ì„¤ëª…**\n",
        "í•´ë‹¹ ì·¨ì•½ì ì´ ë°œìƒí•œ ì´ìœ ì™€ ì½”ë“œ êµ¬ì¡°ìƒ ë¬¸ì œì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "ğŸ’£ **2. ê³µê²© ì‹œë‚˜ë¦¬ì˜¤**\n",
        "ê³µê²©ìê°€ í•´ë‹¹ ì½”ë“œë¥¼ ì–´ë–»ê²Œ ì•…ìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "ğŸ›  **3. ë³´ì™„ ë°©ë²• ë° ê°œì„ ëœ ì½”ë“œ ì˜ˆì‹œ**\n",
        "ë³´ì™„ ë°©ë²•ì„ ì„¤ëª…í•˜ê³ , ë³´ì™„ëœ ì½”ë“œ ì˜ˆì‹œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "âœ… **4. ìš”ì•½ëœ ë³´ì•ˆ ê¶Œê³ ì‚¬í•­**\n",
        "ìš”ì•½ëœ ê¶Œê³ ì‚¬í•­ì„ **ë¦¬ìŠ¤íŠ¸ í˜•ì‹**ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "---\n",
        "\n",
        "ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:\n",
        "\n",
        "ğŸ“„ **ë³´ì•ˆ ë¶„ì„ ë¦¬í¬íŠ¸**\n",
        "\n",
        "---\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant for code security analysis.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=1200  # ìµœëŒ€ ì¶œë ¥ ê¸¸ì´ ì—¬ìœ  ìˆê²Œ í™•ë³´\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "UQ1xthpZuXVt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆì œ ì½”ë“œ & ë ˆì´ë¸”\n",
        "code = \"\"\"\n",
        "user_input = request.args.get('username')\n",
        "query = \"SELECT * FROM users WHERE name = '\" + user_input + \"'\"\n",
        "\"\"\"\n",
        "\n",
        "label = \"SQL_Injection\"\n",
        "\n",
        "# ë³´ê³ ì„œ ìƒì„±\n",
        "report = generate_report(code, label)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gAI-LxQuXTb",
        "outputId": "67a11939-76bd-40ff-fd57-cd55077bdcd9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“„ **ë³´ì•ˆ ë¶„ì„ ë¦¬í¬íŠ¸**\n",
            "\n",
            "---\n",
            "\n",
            "ğŸ“Œ **1. ì·¨ì•½ì  ì„¤ëª…**  \n",
            "í•´ë‹¹ ì½”ë“œì—ì„œ ë°œìƒí•œ SQL Injection ì·¨ì•½ì ì€ ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ë°›ì€ ë°ì´í„°ë¥¼ ì¿¼ë¦¬ì— ê·¸ëŒ€ë¡œ ì‚½ì…í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ë°œìƒí•©ë‹ˆë‹¤. ì‚¬ìš©ì ì…ë ¥ì´ ì¿¼ë¦¬ì— ì§ì ‘ ì—°ê²°ë˜ë¯€ë¡œ ì•…ì˜ì ì¸ SQL ì½”ë“œê°€ ì£¼ì…ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "ğŸ’£ **2. ê³µê²© ì‹œë‚˜ë¦¬ì˜¤**  \n",
            "ê³µê²©ìëŠ” ì‚¬ìš©ì ì…ë ¥ë€ì— `' OR '1'='1' --`ì™€ ê°™ì€ SQL Injection í˜ì´ë¡œë“œë¥¼ ì…ë ¥í•˜ì—¬ WHERE ì ˆì„ í•­ìƒ ì°¸ìœ¼ë¡œ ë§Œë“¤ì–´ ëª¨ë“  ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë…¸ì¶œì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "ğŸ›  **3. ë³´ì™„ ë°©ë²• ë° ê°œì„ ëœ ì½”ë“œ ì˜ˆì‹œ**  \n",
            "SQL Injection ê³µê²©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©ì ì…ë ¥ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤. íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ë‚˜ ORM(Object-Relational Mapping)ì„ ì‚¬ìš©í•˜ì—¬ SQL Injection ì·¨ì•½ì ì„ ë°©ì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ê°œì„ ëœ ì½”ë“œ ì˜ˆì‹œì…ë‹ˆë‹¤.\n",
            "\n",
            "```python\n",
            "user_input = request.args.get('username')\n",
            "query = \"SELECT * FROM users WHERE name = %s\"\n",
            "cursor.execute(query, (user_input,))\n",
            "```\n",
            "\n",
            "ìœ„ ì½”ë“œì—ì„œëŠ” ì‚¬ìš©ì ì…ë ¥ì„ íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬í•˜ì—¬ SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ë¯€ë¡œ SQL Injection ê³µê²©ì„ ë°©ì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "âœ… **4. ìš”ì•½ëœ ë³´ì•ˆ ê¶Œê³ ì‚¬í•­**  \n",
            "- ì‚¬ìš©ì ì…ë ¥ì„ ì¿¼ë¦¬ì— ë°”ë¡œ ì‚½ì…í•˜ì§€ ë§ê³  íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n",
            "- ORMì„ í™œìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ ìƒí˜¸ì‘ìš©ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ì„¸ìš”.\n",
            "- ì…ë ¥ê°’ì„ ê²€ì¦í•˜ê³  í•„ìš”í•œ ê²½ìš° ì´ìŠ¤ì¼€ì´í”„ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ì„¸ìš”.\n",
            "- ë³´ì•ˆ ì·¨ì•½ì ì— ëŒ€í•œ êµìœ¡ ë° ì •ê¸°ì ì¸ ì½”ë“œ ë¦¬ë·°ë¥¼ ì‹¤ì‹œí•˜ì—¬ ì·¨ì•½ì ì„ ìµœì†Œí™”í•˜ì„¸ìš”.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ljmftPDcpIu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22KYy6bspIsq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}